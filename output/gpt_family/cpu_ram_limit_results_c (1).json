[
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.4,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 25979977728,
    "mem_usage_after": 25969000448,
    "elapsed_time_s": 20.296746492385864,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-and-transition-options\" ) ) ; var v = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var d = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var s = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var p = d [ \"src\" ] [ \"src-url\" ] ; var t = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var t = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var h = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var m = m [ \"src\" ] [ \"src-url\" ] ; var n = m [ \"src\" ] [ \"src-url\" ] ; var e = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var r = m [ \"src\" ] [ \"src-url\" ] ; var s = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var t = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var h = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var r = m [ \"src\" ] [ \"src-url\" ] ; var s = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var t = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var e = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var r = m [ \"src\" ] [ \"src-url\" ] ; var s = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var t = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var e = ( var ( \"src\", \"src-data\", \"src-url\" ) ) ; var r = m [ \"src\" ] [ \"src-url\"",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 25969000448,
    "mem_usage_after": 25965723648,
    "elapsed_time_s": 20.278208017349243,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation)\n\nThe New York Times has a story about how the U.S. government is trying to stop the spread of a polio vaccine that is not approved by the U.S. Food and Drug Administration, which has so far refused to approve it. It is one of several examples of what is happening in the United States.\n\nThe report makes clear that the vaccine is not working. There are about 3.6 million cases of polio in the U.S., and in the last year, there have been more than 12,000 cases of polio.\n\nAccording to the U.S. Centers for Disease Control and Prevention, the number of polio cases in the United States is now more than three times higher than in the United States. The CDC estimates that about 7,000 people die every year from polio.\n\nThe report also explains how some of the children in the U.S. have had their immunizations withdrawn because of the disease, and that many of the children who are vaccinated have never been sick.\n\nHere is what the report says:\n\nThe most recent numbers for the year ending March 1, 2010, show that there are about 8,300 people who are living with symptoms of polio in the United States, compared with about 9,400 in 2010.\n\nOf those 8,300 people who are currently living with symptoms, about 7,000 are in the United States, and about 1,100 are in the United Kingdom, the report says.\n\nThis is a large increase from a year earlier, when there were about 2,400 people living with symptoms in the United States. The number of people who are living with symptoms in the United States is now about 7,000 more people than in 2010, and it is expected that by the end of this year, the number of people who are living with symptoms will be about 8,000 more.\n\nThe CDC says it is trying to get the vaccine to the U.S. Children's Hospital in Cleveland, Ohio, to \"make sure it's safe to use.\" The hospital said it has had several tests done and will be reviewing them.\n\nThe report says the government can stop the spread of the vaccine if it \"provides the public with the necessary information and information that will support its efforts to prevent polio.\"\n\nIn the U.K., the government has offered to provide free polio vaccine, which is a form of immunization that is not approved by the U.K. The government says that the",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 25965723648,
    "mem_usage_after": 25966051328,
    "elapsed_time_s": 20.23896074295044,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-tablet\" > <input type=\"text\" name=\"file_file\" value=\"file\" /> <input type=\"text\" name=\"file_file\" value=\"file_file\" /> </table> </div> </td> </tr> <tr> <td class=\"nav-entry\" data-type=\"text\" id=\"nav_tab_text\" > <div class=\"nav-tab-text\"> <div class=\"nav-tab-text\"> <table class=\"nav-tables\"> <tr> <td class=\"nav-title\" data-type=\"text\" id=\"nav_tab_title\" > <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-title\"> <div class=\"nav-tab-",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.4,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 25966051328,
    "mem_usage_after": 25976078336,
    "elapsed_time_s": 19.760565280914307,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-test.html\n\nThis is a great way to test your code for the new features that are coming to the OS X 10.11 operating system.\n\nIn this tutorial we will look at the new features that are coming to the OS X 10.11 operating system.\n\nCheck out the new features in the following sections:\n\nAutomatically add new feature\n\nYou can easily add new features to your project by just using the \"Add new feature\" button. This button will automatically add the new feature to your project if you add it in the current version of OS X.\n\nThis can be done in a few simple steps. First, you will create a new project and click \"Add new feature\" to open it in your browser. This will create a new section on the page that will add the new feature.\n\nIn the new section, you will need to type the following commands:\n\nClick on the \"Add new feature\" button.\n\nClick on the \"Add new feature\" button. Click on \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on the \"Create new feature\" button.\n\nClick on",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 25976078336,
    "mem_usage_after": 25965805568,
    "elapsed_time_s": 19.74047565460205,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-4.jpg\", \"image_inventory\": \"backpack/player/items/all_class/dungeon_pumpkins/dungeon_pumpkins\", \"model_player\": \"models/player/items/all_class/dungeon_pumpkins.mdl\", \"drop_type\": \"none\", \"craft_class\": \"\", \"craft_material_type\": \"\", \"capabilities\": { \"can_craft_mark\": true, \"can_be_restored\": true, \"strange_parts\": true, \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true, \"strange_parts\": true, \"can_killstreakify\": true } \"4\": { \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true, \"strange_parts\": true, \"can_killstreakify\": true } \"5\": { \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true, \"strange_parts\": true, \"can_killstreakify\": true } \"6\": { \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true, \"strange_parts\": true, \"can_killstreakify\": true } \"7\": { \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true, \"strange_parts\": true, \"can_killstreakify\": true } \"8\": { \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true, \"strange_parts\": true, \"can_killstreakify\": true } \"9\": { \"can_card_upgrade\": true, \"can_strangify\": true, \"can_killstreakify\": true, \"can_consume\": true,",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 25965805568,
    "mem_usage_after": 25957212160,
    "elapsed_time_s": 19.753993034362793,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-programming-type]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]\n\n[*]",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.4,
    "cpu_usage_after": 1.8,
    "mem_usage_before": 25957212160,
    "mem_usage_after": 25967931392,
    "elapsed_time_s": 19.78020143508911,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-methods-and-keychain-replaces-the-old-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-the-new-tobias-and-",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 1.5,
    "mem_usage_before": 25967931392,
    "mem_usage_after": 25965101056,
    "elapsed_time_s": 10.758400917053223,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-test-v2.js\n\nLicense\n\nMIT\n\nCopyright (c) 2015 David W. Smith <dwsmith@saint.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 1.5,
    "mem_usage_before": 25965101056,
    "mem_usage_after": 25977352192,
    "elapsed_time_s": 20.03636908531189,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-2.0.4-1.1.1-build.html\n\n1.2.0-beta\n\nAdd the latest beta 2.0.4 version (0.4.0) of HTML5 and CSS5 to the main page.\n\n1.2.1-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.2-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.3-beta\n\nAdd the latest beta 2.0.4 beta 2.0.4 to the main page.\n\n1.2.4-beta\n\nAdd the latest beta 2.0.4 beta 2.0.4 to the main page.\n\n1.2.5-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.6-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.7-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.8-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.9-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.10-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.11-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.12-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.13-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.14-alpha\n\nAdd the latest alpha 2.0.4 beta 2.0.4 to the main page.\n\n1.2.15-alpha\n\nAdd the latest alpha 2.0.4 beta 2.",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.7,
    "cpu_usage_after": 2.8,
    "mem_usage_before": 25977352192,
    "mem_usage_after": 25982754816,
    "elapsed_time_s": 20.599265098571777,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-in-production-4.html\n\nhttp://www.mccain.com/blog/2011/03/27/possible-solution-to-reduce-the-carbon-cycle-of-climate-change/\n\nhttp://www.thegreenwatch.org/2011/03/27/possible-solution-to-reduce-the-carbon-cycle-of-climate-change/\n\nhttp://www.renewableenergy.org/blog/2011/03/27/possible-solution-to-reduce-the-carbon-cycle-of-climate-change/\n\nhttp://www.globalresearch.ca/environment/2013/12/possible-solution-to-reduce-the-carbon-cycle-of-climate-change/\n\nhttp://www.pancyslaw.com/blogs/mccain-and-global-warming-2013/\n\nhttp://www.sciencemag.org/content/early-interviews/2010/05/possible-solution-to-reduce-the-carbon-cycle-of-climate-change-12/\n\nhttp://www.renewableenergy.org/blog/2011/03/27/possible-solution-to-reduce-the-carbon-cycle-of-climate-change/\n\nhttp://www.globalresearch.ca/environment/2013/12/possible-solution-to-reduce-the-carbon-cycle-of-climate-change/\n\nhttp://www.pancyslaw.com/blogs/mccain-and-global-warming-2013/\n\nhttp://www.pancyslaw.com/blogs/mccain-and-global-warming-2013/\n\nhttp://www.pancyslaw.com/blogs/mccain-and-global-warming-2013/\n\nhttp://www.globalresearch.ca/environment/2013/12/possible-solution-to-reduce-the-carbon-cycle-of-climate-change-12/\n\nhttp://www.pancyslaw.com/blogs/mccain-and-global-warming-2013/\n\nhttp://www.pancyslaw.com/blogs/mccain-and-global-warming-2013/",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 2.8,
    "mem_usage_before": 25982754816,
    "mem_usage_after": 25976336384,
    "elapsed_time_s": 20.621193885803223,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-guide-for-digital-media-reform-2017-05-22-us\"},{\"id\":\"groupon-deals-1218\",\"name\":\"groupon-deals-1218\",\"description\":\"groupon-deals-1218\"},{\"id\":\"groupon-deals-1217\",\"name\":\"groupon-deals-1217\",\"description\":\"groupon-deals-1217\"},{\"id\":\"groupon-sale-425\",\"name\":\"groupon-sale-425\",\"description\":\"groupon-sale-425\"},{\"id\":\"groupon-deals-1222\",\"name\":\"groupon-deals-1222\",\"description\":\"groupon-deals-1222\"},{\"id\":\"groupon-sale-684\",\"name\":\"groupon-sale-684\",\"description\":\"groupon-sale-684\"},{\"id\":\"groupon-deals-1214\",\"name\":\"groupon-deals-1214\",\"description\":\"groupon-deals-1214\"},{\"id\":\"groupon-sale-684\",\"name\":\"groupon-sale-684\",\"description\":\"groupon-sale-684\"},{\"id\":\"groupon-deals-1213\",\"name\":\"groupon-deals-1213\",\"description\":\"groupon-deals-1213\"},{\"id\":\"groupon-deals-1221\",\"name\":\"groupon-deals-1221\",\"description\":\"groupon-deals-1221\"},{\"id\":\"groupon-deals-1220\",\"name\":\"groupon-deals-1220\",\"description\":\"groupon-deals-1220\"},{\"id\":\"groupon-deals-1218\",\"name\":\"groupon-deals-1218\",\"description\":\"groupon-deals-1218\"},{\"id\":\"groupon-deals-1215\",\"name\":\"groupon-deals-1215\",\"description\":\"groupon-deals-1215\"},{\"id\":\"groupon-deals-1214\",\"name\":\"groupon-deals-1214\",\"description\":\"groupon-deals-1214\"},{\"id\":\"groupon-deals-1212\",\"name\":\"groupon-deals-1212\",\"description\":\"groupon-deals-1212\"},{\"id\":\"groupon-deals-1216\",\"name\":\"groupon-deals-1216\",\"description\":\"groupon-deals-1216\"},{\"id\":\"groupon-sale-684\",\"name\":\"groupon-sale-684\",\"description\":\"groupon-sale-684\"},{\"id\":\"groupon-sale-683\",\"name\":\"groupon-sale-683\",\"description\":\"groupon-sale-683\"},{\"id\":\"groupon-sale-774\",\"name\":\"groupon-sale-774\",\"description\":\"groupon-sale-774\"},{\"id\":\"groupon-sale-674\",\"name\":\"groupon-sale-674\",\"description\":\"groupon-sale-674\"},{\"",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 4.1,
    "cpu_usage_after": 2.8,
    "mem_usage_before": 25976336384,
    "mem_usage_after": 25982935040,
    "elapsed_time_s": 20.677862644195557,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-system-on-linux-x86_64-2.4.2-i586-2.txz: Upgraded.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Add missing information.\n\nc/c++/include/macros/type_if_not_fetch.h: Fix the return type of type_if_not_fetch.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/macros/type_if_not_fetch.h: Avoid missing information.\n\nl/pc/c++/include/",
    "model_variation": "base",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.7,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 27306856448,
    "mem_usage_after": 27378163712,
    "elapsed_time_s": 48.97089719772339,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation.html?tag=rss&utm_source=feedburner&utm_medium=rss\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502686\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502685\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502684\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502683\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502682\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502681\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502680\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502679\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502678\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502677\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502676\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502675\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502674\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502673\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502672\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-16502671\n\nhttp://www.bbc.co.uk/news/uk-england-west-scots-165026",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 27378163712,
    "mem_usage_after": 27384029184,
    "elapsed_time_s": 47.23272919654846,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation method of generating HTML from the user's input.\n\nThe HTML5 input method supports:\n\nIn-line validation of HTML elements\n\nHTML validation, including case-insensitive matching and escaping\n\nIn-line validations of the content attribute\n\nThe following markup contains an example of the input method.\n\n<input type=\"text\" name=\"name\" value=\"John\" />\n\nThe following example shows how the input method works.\n\n<input type=\"text\" name=\"name\" value=\"John\" /> <input type=\"submit\" value=\"Submit\"/>\n\nExample 1: input method for an input box\n\nThe following example shows how the input method works.\n\n<input type=\"text\" name=\"name\" value=\"John\" /> <input type=\"submit\" value=\"Submit\"/>\n\nExample 2: input method for a button\n\nThe following example shows how the input method works.\n\n<button type=\"submit\" value=\"Submit\" />\n\nExample 3: input method for a drop-down\n\nThe following example shows how the input method works.\n\n<input type=\"text\" name=\"name\" value=\"John\" /> <button type=\"submit\" value=\"Submit\" />\n\nExample 4: input method for a text field\n\nThe following example shows how the input method works.\n\n<textarea name=\"name\" name=\"value\" size=\"10\" checked=\"checked\" name=\"value\" size=\"10\" text=\"John\">\n\nIn-line validations of the content attribute\n\nThe following markup contains an example of the input method.\n\n<input type=\"text\" name=\"name\" value=\"John\" /> <textarea name=\"value\" name=\"name\" size=\"10\" checked=\"checked\" name=\"value\" size=\"10\" text=\"John\"/>\n\nThe following example shows how the input method works.\n\n<input type=\"submit\" value=\"Submit\"/>\n\nExample 5: input method for an element\n\nThe following example shows how the input method works.\n\n<div class=\"container\"> <div class=\"row\"> <div class=\"col-md-12\"> <div class=\"col-md-8\"> <input type=\"text\" name=\"name\" size=\"10\" value=\"John\" /> </div> </div> </div> </div>\n\nThe following example shows how the input method works.\n\n<",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.6,
    "mem_usage_before": 27384029184,
    "mem_usage_after": 27382460416,
    "elapsed_time_s": 47.149863958358765,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-2.html\n\nhttp://www.napalabras.org/\n\nhttp://www.napalabras.org/ http://www.sphinx.org/\n\nhttp://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.org/ http://www.sphinx.",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.8,
    "cpu_usage_after": 0.9,
    "mem_usage_before": 27382460416,
    "mem_usage_after": 27387260928,
    "elapsed_time_s": 45.591644048690796,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-function: function(string, function(value) { var value = '$'; if (string.indexOf(value, '#') === -1) { value = '#'; } else { value = '$'; } return value; })(); </script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/libs-angularjs/1.10.0/angular.min.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/libs-angularjs/1.10.0/angular-bootstrap.min.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/libs-angularjs/1.10.0/angular.min.js\"></script> </body> </html>\n\nThe above code is actually a single file. Here is the resulting HTML:\n\n<html> <head> <title>ng-angular</title> <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/libs-angularjs/1.10.0/angular.min.css\"> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/libs-angularjs/1.10.0/angular.min.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/libs-angularjs/1.10.0/angular-bootstrap.min.js\"></script> </head> <body ng-controller=\"app\"> <form ng-submit=\"{{ action}}\" ng-model=\"myForm.value\" ng-controller=\"myForm.value.value\" ng-submit=\"{{ action}}\" ng-click=\"{{ action}}\" ng-click=\"{{ action}}\" ng-on=\"myForm.value.value.value.click\" ng-on=\"myForm.value.value.value.click.click\" ng-click=\"{{ action}}\" ng-on=\"myForm.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value.value",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 2.1,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 27387260928,
    "mem_usage_after": 27387936768,
    "elapsed_time_s": 45.966381549835205,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation: utf-8; font-weight: normal; line-height: 1.4em; font-family: \"Mozilla Firefox\",Arial,sans-serif; text-align: center; padding-left: 1.25em; padding-right: 1.25em; margin-left: 1.25em; margin-right: 1.25em;\"> </div> <div class=\"new_tab\"> <div class=\"new_tab-content\"> <div class=\"new_tab-header\"> <h2>New Tab</h2> <div class=\"tab-content\"> <div class=\"tab-header\"> <h1>New Tab</h1> <div class=\"tab-header-text\"> <h2>New Tab</h2> </div> </div> </div> <div class=\"new_tab-content\"> <div class=\"new_tab-content\"> <div class=\"tab-header\"> <h2>New Tab</h2> <div class=\"tab-header-text\"> <h2>New Tab</h2> </div> </div> </div> <div class=\"new_tab-content\"> <div class=\"new_tab-content\"> <div class=\"tab-header\"> <h2>New Tab</h2> <div class=\"tab-header-text\"> <h2>New Tab</h2> </div> </div> </div> </div> <div class=\"new_tab-content\"> <div class=\"new_tab-content\"> <div class=\"tab-header\"> <h2>New Tab</h2> <div class=\"tab-header-text\"> <h2>New Tab</h2> </div> </div> </div> </div> <div class=\"new_tab-content\"> <div class=\"new_tab-content\"> <div class=\"tab-header\"> <h2>New Tab</h2> <div class=\"tab-header-text\"> <h2>New Tab</h2> </div> </div> </div> </div> <div class=\"new_tab-content\"> <div class=\"new_tab-content\"> <div class=\"tab-header\"> <h2>New Tab</h2> <div class=\"tab-header-text\"> <h2>New Tab</h",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 1.0,
    "mem_usage_before": 27387936768,
    "mem_usage_after": 27392946176,
    "elapsed_time_s": 45.91275453567505,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-systems.html\n\n\"The text generation system uses a text-generating engine to generate new text. The text is then embedded in an HTML document, which is then displayed on a web page. The text is presented in the form of a list of selected text elements, each of which is presented as a paragraph, a sentence, or a list of sentences. Each of these elements is presented as a separate line item in the document.\"\n\nhttp://www.text-gen.org/\n\n\"The text generation system uses a text-generating engine to generate new text. The text is then embedded in an HTML document, which is then displayed on a web page. The text is presented in the form of a list of selected text elements, each of which is presented as a paragraph, a sentence, or a list of sentences. Each of these elements is presented as a separate line item in the document.\"\n\nhttp://www.text-gen.org/\n\n\"The text generation system uses a text-generating engine to generate new text. The text is then embedded in an HTML document, which is then displayed on a web page. The text is presented in the form of a list of selected text elements, each of which is presented as a paragraph, a sentence, or a list of sentences. Each of these elements is presented as a separate line item in the document.\"\n\nhttp://www.text-gen.org/\n\n\"The text generation system uses a text-generating engine to generate new text. The text is then embedded in an HTML document, which is then displayed on a web page. The text is presented in the form of a list of selected text elements, each of which is presented as a paragraph, a sentence, or a list of sentences. Each of these elements is presented as a separate line item in the document.\"\n\nhttp://www.text-gen.org/\n\n\"The text generation system uses a text-generating engine to generate new text. The text is then embedded in an HTML document, which is then displayed on a web page. The text is presented in the form of a list of selected text elements, each of which is presented as a paragraph, a sentence, or a list of sentences. Each of these elements is presented as a separate line item in the document.\"\n\nhttp://www.text-gen.org/\n\n\"The text generation system uses a text-generating engine to generate new",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.4,
    "cpu_usage_after": 1.6,
    "mem_usage_before": 27392946176,
    "mem_usage_after": 27407835136,
    "elapsed_time_s": 49.426467180252075,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-toolkit.html\n\nhttp://www.pinterest.com/pin/146080362034187513/\n\nhttp://www.google.co.uk/search?q=haystack+generator&ie=UTF-8&source=lnms\n\nhttp://www.cogent.org/wiki/Determine_Type_of_File_to_Generate_in_Java\n\nhttp://docs.oracle.com/javase/9.0/docs/com/javase/12/en/generator.html\n\nhttp://www.sourceforge.net/projects/generate-javaceer/\n\nhttp://www.gcc.gnu.org/cplusplus/\n\nhttp://www.gcc.gnu.org/c++/5/g++/5/include/generate.h\n\nhttp://www.jemalloc.org/\n\nhttp://www.python.org/\n\nhttp://www.python-dev.org/\n\nhttp://www.python-source.org/\n\nhttp://www.python-info.org/\n\nhttp://www.python.org/trac/\n\nhttp://www.python-info.org/trac/html/\n\nhttp://www.python.org/trac/html/python-info.html\n\nhttp://www.python-info.org/trac/html/python-docbook.html\n\nhttp://www.python.org/trac/html/python-docbook.html#gensubscribe\n\nhttp://www.python-info.org/trac/html/python-docbook.html#stub\n\nhttp://www.python-info.org/trac/html/python-docbook.html#show\n\nhttp://www.python-info.org/trac/html/python-docbook.html#get\n\nhttp://www.python-info.org/trac/html/python-docbook.html#getlist\n\nhttp://www.python.org/trac/html/python-docbook.html#gettext\n\nhttp://www.python-info.org/trac/html/python-docbook.html#getsubscribe\n\nhttp://www.python",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 1.7,
    "mem_usage_before": 27408351232,
    "mem_usage_after": 26931601408,
    "elapsed_time_s": 46.12989282608032,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation, which means that you can choose to have your text generated with a single font, or with multiple fonts.\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name font-family text-transform-name font-weight text-weight\n\nThis font is used for the \"text-transform\" property.\n\nIf you are using a different font, you can specify the name of the font in the project.\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name text-transform-weight text-weight font-family text-transform-weight\n\nThis font is used for the \"text-transform\" property.\n\nIf you are using a different font, you can specify the name of the font in the project.\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name text-transform-weight text-weight font-family text-transform-weight font-weight\n\nThis font is used for the \"text-transform\" property.\n\nIf you are using a different font, you can specify the name of the font in the project.\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name text-transform-weight text-weight font-family text-transform-weight font-weight\n\nThis font is used for the \"text-transform\" property.\n\nIf you are using a different font, you can specify the name of the font in the project.\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name text-transform-weight text-weight font-family text-transform-weight font-weight\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name text-transform-weight text-weight font-family text-transform-weight font-weight\n\nThe following table shows the font names used in the project.\n\nFont Name Description font-family-name text-transform-name text-transform-weight text-weight font-family text-transform-weight font-weight\n\nThe following table shows the font names used in the project.",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 1.6,
    "mem_usage_before": 26931085312,
    "mem_usage_after": 26927681536,
    "elapsed_time_s": 45.91075277328491,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation/html/index.html#image-3044\n\n* A lot of people were asking me about the old image that was posted from the forums. I decided to make this image for the site.\n\n* http://www.matt-gumpert.com/\n\n* http://www.facebook.com/matt-gumpert\n\n* http://www.twitter.com/matt-gumpert\n\n* http://www.instagram.com/matt-gumpert\n\n* http://www.youtube.com/matt-gumpert\n\n* http://www.instagram.com/gumpert.jpg\n\n* http://www.youtube.com/user/matt-gumpert\n\n* http://www.linkedin.com/in/matt-gumpert/\n\n* http://www.myspace.com/matt-gumpert\n\n* http://www.instagram.com/matt-gumpert/\n\n* http://www.linkedin.com/in/matt-gumpert/\n\n* http://www.facebook.com/matt-gumpert\n\n* http://www.twitter.com/matt-gumpert\n\n* http://www.instagram.com/matt-gumpert/\n\n* http://www.linkedin.com/in/matt-gumpert/\n\n* http://www.myspace.com/matt-gumpert\n\n* http://www.instagram.com/matt-gumpert/\n\n* http://www.linkedin.com/in/matt-gumpert/\n\n* http://www.google.com/\n\n* http://www.linkedin.com/in/matt-gumpert\n\n* http://www.youtube.com/user/matt-gumpert\n\n* http://www.youtube.com/user/matt-gumpert/\n\n* http://www.twitter.com/matt-gumpert\n\n* http://www.instagram.com/matt-gumpert/\n\n* http://www.linkedin.com/in/matt-gumpert/\n\n* http://www.google.com/",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 2.6,
    "cpu_usage_after": 3.0,
    "mem_usage_before": 26925617152,
    "mem_usage_after": 26918612992,
    "elapsed_time_s": 53.12310862541199,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-options': { 'text-transform': 'uppercase', 'text-transform-origin': 'top', 'text-transform-size': '14px', 'text-transform-font-size': '15px', 'text-transform-border-radius': '5px', 'text-transform-border': '1px solid black', 'text-transform-font-family': 'Times New Roman', 'text-transform-font-size': '14px', 'text-transform-line-height': '18px', 'text-transform-punctuation': '!', 'text-transform-uppercase': '!', 'text-transform-italic': '!', 'text-transform-underline': '!', 'text-transform-underline-stroke': '!' } }\n\nNote: The default font size is 13px.\n\nStep 4: Add a custom font to the CSS\n\nNow that we have a set of fonts in place, we need to add the custom font to the CSS. This can be done with a simple CSS rule.\n\n.new-header { font-family: 'Times New Roman', Times New Roman; font-size: 13px; padding: 3px 0px; }\n\nStep 5: Add a font-face\n\nAfter adding the custom font, we will need to add the font-face, which will be displayed on the header. It should look like this:\n\n.new-header { font-family: 'Times New Roman', Times New Roman; font-size: 13px; font-family: Arial, sans-serif; font-weight: bold; font-style: normal; }\n\nStep 6: Add a custom background\n\nNow that we have a font in place, we will need to add a custom background to the header. The default background for the header is shown in the image below, but we can also add our own custom background.\n\nStep 7: Add an image\n\nWe will need to add a custom image to the header. The image for this example is the image from our WordPress theme.\n\nStep 8: Change the background color\n\nTo change the background color of the header, we will need to change the background color of the image. To change the background color of the image, we will need to change the background color property of the image.\n\nWe will need to change",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 5.6,
    "cpu_usage_after": 3.1,
    "mem_usage_before": 26918612992,
    "mem_usage_after": 26926952448,
    "elapsed_time_s": 41.40328311920166,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation, but you could use a text-to-speech engine like Speex to handle it, too.\n\nOne of the more useful features of the Windows Phone 8.1 operating system is its native Windows Phone 8.1 app store, which is designed to let you download apps from a variety of different sources and install them on your device. While we don't yet know if this means that the Microsoft Store will be able to handle all the apps you might want to install on your phone, it's a welcome addition to the Windows Phone 8.1 ecosystem.\n\nMicrosoft Store integration is likely to be a key part of the Windows Phone 8.1 operating system, as it is with Windows Phone 7.\n\nThe Microsoft Store on Windows Phone 8.1 is similar to the store on Windows Phone 7. However, it's made to look like a Windows Phone Store by default, with its default tile design and overall design that's similar to Windows Phone 8.1.\n\nThe Microsoft Store has been around since Windows Phone 8.0. It was originally designed to be a direct link to the Windows Phone Store, so you don't have to worry about trying to download apps from another device. It's been around for a few years now, and is still in its infancy.\n\nThe Windows Phone Store's design is similar to the Windows Phone 8.0 store, which has been around for a few years now.\n\nWhen you're using the Windows Phone Store on your phone, the app's tiles are grouped into categories, each of which has a different layout. When you tap on one of those categories, the Windows Phone Store app opens up to display the app in that category. The Windows Phone Store app also displays a list of the apps you've downloaded, and you can also tap on the app you want to install and it'll open up to install the app as well.\n\nThe Windows Phone Store on Windows Phone 8.1 can be downloaded from the Windows Phone Store website.\n\nWhile the Microsoft Store on Windows Phone 8.1 is currently available for free download, the app will be going free with Windows Phone 8.1, and a Windows Phone 8.1 version will be available when the update is released in November.",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 1.2,
    "cpu_usage_after": 3.0,
    "mem_usage_before": 26928500736,
    "mem_usage_after": 26923040768,
    "elapsed_time_s": 46.022456884384155,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-tools.com/html/index.html#samples\n\nI have several of these on my computer. I am not sure if I should tell you about them. I think you will find them useful and interesting.\n\nI have a couple of them on my Macbook Pro. I am not sure if I should tell you about them. I think you will find them useful and interesting.\n\nI have an AppleScript file on my computer. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a C# file on my computer. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a JSON file on my computer. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a C++ file on my computer. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a text file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have an SQL file on my computer. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a C++ class file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a C# class file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a Javascript file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a JavaScript file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a C# class file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a C++ class file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.\n\nI have a JSON file on my Macbook Pro. I have no idea where it is and it is not clear if it should be included or not.",
    "model_variation": "base",
    "model_base": "openai-community/gpt2-medium"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.5,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 26127781888,
    "mem_usage_after": 26111930368,
    "elapsed_time_s": 17.795719861984253,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation\n\nH/T: A. I. Aukerman, B. G. E. Hoh, Geog. & T.\n\nV. (. (C. S.)\n\nI.\n] (--:,-,-,-,-,-,-)---,-,,-)-,\n._in.\n\nA/I.\n;,,.\n.\nB/.\n(\n-,-,-,-,-.\n-(\n---\n\n-,-,-,-.\n\n\"The, the to, a, the the the and the to and the to a\n\" a, the, the, the, the, the, the, the\n(\n<\n%\n\u2014,-,-,-,-(,-)-(,-.-(,-)-(,-)-(\n -,-,-(,-)-(,-)-(,-)-(,-)-(,-)-(,-)-(,-)-(,\n\" the. the, the, the\" a, the the the the a the the the, the the the the the a the the the the the the\n*\n(\n<\n/1>\n(\n\n-,-(,-)-(,-)-(,-)-(,-.-(,-)-(,-)-(,-(,-)-(,-(,-)-( (-,-)-(,-)-(,-)-(,\n\n\" the. the, the\" a, the the the the,\n\n(\n-,-(,-)-(,-.-(,-.-(,-.-(,-.-(,-)-(,-,-)-(,\n\" the. the, the, the\" a the, the the the the the the the\n\u2026\n\n(\n\" the. the, the\" a, the the the the, the the the the the\n, the\n\n(\n\n-,-(,-)-(,-.-(,,-(,-,-)-(,-)-(,-(,-,-)-(,-(,-,-)-(,\n\n\" the. the, the, the\" a the the, the the the the the,\n\n(\n[/|\n\u2014,-(,-)-(,-.-(,)-(,)-(,-)-(,-(,-)-(,-,-(,-,-)-(,\n\" the. the, the. the\" a the the, the",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 26111930368,
    "mem_usage_after": 25761247232,
    "elapsed_time_s": 16.609387636184692,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation in a new, the \"Aeons\" and by the 'c' in the \"fascinating-wacom-a\" to be-pap---s. (-. for. the-rein-on '- of. and.\n... and in the-fascinating-waci-/- in the-cis-and. a-and.\n2. that as a the-a. for, and a-in-a. and. and. and. a-l-l. a-m. and. and. and. a-c.', in the-h-a-m. one. in the-h-en-ed. one. \" the-a\" and.\n3. at. and. a- (-. and. a-, in--en-ed. one. in-en-e-n-/-in-en--, in-to-en-. in-to-en-l-e-on-fascinating-wacom-a. one.\nn. a-. the-a. the-a. a--h. a--k-, a-h--.\np. as a- on, and. as a-c' on. a--l-a. and. a-c'-l-a. and. a-j. and. a-, in-to\u2014e-a. in-to-en-l-e-on-fascinating\" wacom-a. one.\n\n-. and. a-, in the-a. for, and. a, in-to\u2014e-a-, in|en-l-e-on-fascrinking-wacom-a. one, in-to\u2014e-a-, in-to\u2014e-a-, in-to\u2014e-a-, in-to--e-a-, in-to--e-a, in-to--e-a-, in-to--e\u2014e-a-, in-to--e-a-, in-to--e-a-, in-to--e, in-to--e-a-, in-to--e, in-to--e, in|en-l-e, in-to",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 25761247232,
    "mem_usage_after": 25760972800,
    "elapsed_time_s": 16.505237817764282,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-on-in-pagoda-t-8-a-0-d,l--A.e2-7.nz.html,\n\"h\" : \"Ginger-H-T/4-l-A\", \"n\":, \"\" : \"Pink-C--4-P\", \"\"+n:i:z\\ n : GEM N. C. -H, the. (f. 3s. and. the, and the, and the ((\n\", and\", and\", and\" of- a-g, and\"(, the (in (\n\"\n\nThe (s. a -. and\"). the,\n\n\", (a-,\n\" \".\n(n- a- the, (in (\" (\n\u2014, and\"\n\n-. the, and\"( (m-, and\"\n\", (- and(- the\", and\"and,\"\n\n\"\n\n\"(. and\"(and (- and (t- the, and\"\n\", and \"( and\", and\"(, and\"\n- and(\u2014\", and\"(, and(to-\n\u2014\", and\"(. and\"( (/ and\u2014 and(- and(, and\"\n\n\", and\"(. and \"( and,\" and\"(and\"(, and\"\n\n\"(n- and(), and\"(, and\"(, and\"( and(t-\n\", and(w- and(, and(, and-\n\n\"( and\"(n- and(, and\"(t- the, and(t-\n\", and(/and(t-\n(and(t-the, and(t-the, and(t-the, and(t-\n\", and(t-the, and(t\",, and(t-the, and(t-the, and(t[:- the, and(t-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t>-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t-the, and(t>-the,",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 25760976896,
    "mem_usage_after": 25760931840,
    "elapsed_time_s": 15.261082410812378,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-a-cls, \"n:cmath-bounce\"; classmethod= \"math.randn\"; pb=array(5, [,--1,,--16,-2,-11,-26,-158,-118,1,0,-301]); all_elements=(1, and 0); this.y.blur_a = '0'; invert_i2c=new ImageJson(new ImageJson(5, 0, (dinput__i2c) + (dinput_i2events),\n\"f\"; for(i = 1; i < (dinput_i2events.dst_cx) + 5; i++) { the_elements[i] = the_e://_f.dst_cxx.t.\n\",\".\n...l.n.l\": invert_i2c(i); to_elements.invert_i2c(this.y.blic_cx_i2c); inthrottle_cx=invert_i19c(the_elements[i]); the_e10cx=inthroave_cx; invert_i0c=outvert_i8c(the://_f.dbay_cxx.t.\n\n\", this.y.blic_cx_i2results.invert_i5cx, outverti_i1c=outfifc_cx); the_e10cx_i2c.outthrottle_cx=outthrottle_cx; this.y.flat_a=invert_i23c(this.y.flat_a); inthrottle_cx=in\n---end loop---\n- #S2: A list of to-dos, a to-read, and to-moves, per-head, inline, to-nth, (-/f/, to-r/, and to-.b--n/-,\n-/:.in-n/:- to-n/, in-e/:- to-e/\n-/-e1/:- to-e1/:- to-a/:- to-h/\n-/-x/:- toko/:",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.9,
    "mem_usage_before": 25760931840,
    "mem_usage_after": 25751707648,
    "elapsed_time_s": 15.233248710632324,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-1.2.17-1.9.jar) UCHIJAAAA Mekanism{1.70-dev-5a926-9.b0-abc443.zip] Unloaded->Constructed->Pre-initialized->InitializedLoader{0.49.c-r7_1.7.3}->DownloadKnownClientCfg{2\":\"r7_1.7.3\",\"BETA\":\"1.7.3\"}, FML{5.47.4.a810}->Available ForgeRelocation{1>=0.2.8.c6}->Available MFR Compat Forestry Trees{1.17.2.9.1}://mods://r70-r7-7.2.-r6.b1-9.b3--7.p-1.6.r-5.1.i.b.a.p.2.n.a.r.a.r.b.a.r.f.i.b.i.i.s.b.s.c.i.c.i.e. aa.g.\n\n{0.1} [Mekanism] (Mekanism-1.7-2|1(1.11.12)})\n\n{1.1} - [ChickenChunks]|classpath(unknown)\n\u2026\n\u2014 Initialize all the blocks within the 4/20/14/0.3 block in the MFTagLoader class.\n\"Particles\" does not exist in the OpenMods and MineFactoryReloaded data\n \u2014 Loading \"Particles\" in \"OpenBlocks\" will not preserve the missing data\n\"SeederRecipe\" does.\n\"SeederRecipe\" in \"OpenMods\" can overwrite the \"Particles\" data\n\"IWG_Themes\" has the\n> [<cols:6>]\n\"The.IWG_SeederRecipeCompatibilityCompatibilityCompatibilityCompatPlugin[SeederRecipeCompatibilityCompactor]:maven-0.1.i7-1.7.4\"}\n.\nIndeed it and, exactly as poised to assume the only biological, in-sand-seeds-d-nasm (-f-a-,.a-a-,a-i--p-b)\n\"NA_TribalAffinityAchievements\"",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.9,
    "mem_usage_before": 25751707648,
    "mem_usage_after": 25756880896,
    "elapsed_time_s": 15.196528673171997,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation;width:100%;background:url(%%screenshot%%) no-repeat;text-decoration:none;}\n\u00b6\n(1)\n\nThe UML for other.\n[C1]\n\u2014 in the DAW, that, or the Biz, the. The in the Dadvertising, that://l-e--c-2.\n[-d+-3. the (and, and and in (C:. the a \", (, and, and and in, the I, the-, the is, the to, etc.) in, the, etc. and in (C:. the, and, and, and the, the, the in, the, the\nt. \"is, the to, etc.) in, etc. \"- and in (C:, and, and in, the, the and, the, the and, the, the-, the, the and the-, the. (C:. the, in, the-, the-, the-, the, the-, the-, the-, the-, the-, the-, the-, the-, the-, the-, the,\n\nand (C, the-, the-, the-, the-/. and the-, the-, the, the-, the, the-, the-, the (C:. the-, the, the. and, the- and, the-, the-, the-, the-, the-, the-, the-, the-, the-, the-, the-, the-, the, the, the-, the-, the-, the-, the, the-, the, the-, the\n''. the-, the-, the-, the-, the-, the-, the, the-, the in, the-, the-, the-, the-.\n\n\"The-, the-, the-, the-, the-, the-, the-, the-, the-, the-, the-, in, the-, the the-, the' the-, the-- and the-, the. (C:. the, in-, in-, the, in, the-, the-, the, the-, the-, the-, the-, the-",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 2.3,
    "cpu_usage_after": 1.6,
    "mem_usage_before": 25756880896,
    "mem_usage_after": 25763962880,
    "elapsed_time_s": 15.621379137039185,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-and-pagination-in-kistad-in-rudvink.jpg\n\n- the G-s-I, a (The Internet [a work of art that calls itself a theorems and is, of the Internet, in the, a work://w0ms.d-c.ac.mx) in The Internet, a (a \"The Internet \", \", and \", in that and, the, the, the\n\",\n\u2014 an- of \"is, in that, the, and, the in, and\"), the S (a \"in- the\n\" to and\") a.\n\"a, the, in that, the, in,\" (c. the the \"\nand,\" in\n\na. the,\n\nis, in that, the in,\" in, in that,\n\nthe in,\" the and the, the in,\" the and, the in,\" the and the in,\" the in,\" the and the in,\" the in,\" the in,\" the in,\" the\n\" in,\" the in,\" the in,\" the in,\" the in,\" the in,\" the a.\n\nThe-\n. the. in,\" the in,\" the in,\" the in, in,\" the in, in, in, in,\" the in, in, in, in, in a.\n \u2014 in, a\n\n-\n. in,\" the in, the in, in, in, in, in, in, in, in, in, in, in, in, in,\" the in, a.\n'', a. the in,\" the the, in, the in, in, in, in (- the,\" the in,\" the in, the in, in, in, in, in,\" the in, a.\n(. in, a\n\"\n.\n'', a. the in, the in.\n\n'', a, the in, the in, the in, the in, in.\n--\n\n(.\n-\n', a\n--, a\n\u2014, a\n\",\n\"\n\nA B C D E F G H I J K L M N O Q R T U V W X Y Z\n~, a. the, a, a.\n-\n\ni\n--, a. the. a. the. a, a.\n\", a. the. the.",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 1.6,
    "mem_usage_before": 25763962880,
    "mem_usage_after": 25759809536,
    "elapsed_time_s": 15.345646858215332,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation\" \"1\" } }, { \"catentry_id\" : \"102425147\", \"channelAvailability\"): \"BuyableInstoreAndOnline\", \"inventoryQuantity\"\n\n[24] \"15.0\", 0.0, 3355.8.\n\u2014 CRSM Staff. [B2]\n.\n\"N.C. The N.C. The N\" (The, \"C\", \"The, \"is, \" in \",\" in, \"is, \"in\", \"is\", \"is, and \"is, and \"is, and \"is, and \"is, and \"is, and, and \"is, and \"is, and \"is and, and \"is, and \"is, )\n\u2026\n\nIt's by the, '2. the and \". the, in, \". the, and \". the, in, \":, in, \" in, \", and \". the, in, \" in, the, in, \", and, the in, the, in, the, in, the, in ( the, the, in, the, in, the, in, \", in, the, in, the, in, the, in, the, in, the, in the, the, the, in, the, the, the, the, in, the, the, in ( the, the, and the, in, the, the, the, in, the, in ( the, the, and enough, in ( the, and the, the, and the, in, the, the, in, the in, in, the, the, in ( the, and the, in, the, the, the, in, the in, the in ( the, and the, since, the, the, since, the, since, the, since, the, the, since, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,, the, the, the, the, the, and the, in, the, the ( in, and the, the, the, and in, the (, the, and, the, the, in, the, the, the, and in, the, the ( in; and the, and the, and the, the, in, the ( the, and the",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 2.2,
    "cpu_usage_after": 1.6,
    "mem_usage_before": 25759809536,
    "mem_usage_after": 25757429760,
    "elapsed_time_s": 15.117215156555176,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation, in:\n\"The Ingestion of PN and WSE, the (I. thea-a. (e. thes. (. with a. ', and the \"n. the. thea-.-at,\nn. the-. and the- and the (2. thea-n. thea-,\nin. thea-n. thea-n. and the-\nthe-a. (, and thea-n. thea-n. and the-\nthe-a. (2. thea[',\nthea-n. the-a. and the-\nthen. thea-n. and then. the-\nthea-.\n\n\"\n\n-. thea-n. Thea-.\n\n[S818]\n\u2014 \", a'y thea-. (, thea-n. the-a. and\n\"\n(. thea. thea-n. the, thea. in thea-n. the\n\u2026 and then. in thea-n. thea-n. and the-\n. thea-. (a-n, then. then. and\n\"\n\"\n. thea-. thea-. and then. thea-n. and thea-n.\n. Thea-. thea-. and then- thea-n. and the-\n\"\n\"thea-. thea-. and then-thea-.\n\"\n\nand then. in then. the,\n\u2014\n\"thea-. and then. thea-n. and thea-n-\n\nthea-. (a-n, then-thea-. and-\n\"\n>\n\n(1. thea-. thea-. and-\n\"thea-n. and the-\n\"thea-n. and thea, thea, thea-n.\n\n\"and thea-n-thea-. (a-n,\n(a-n, then-. thea-. and-\n\n\"the. thea-. thea-. and-\n:\n[i. thea-n. thea-n. and-\n]\n\"thea-. thea-n-thea-\n\"\n(1. thea-.",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.8,
    "cpu_usage_after": 3.5,
    "mem_usage_before": 25757429760,
    "mem_usage_after": 25770053632,
    "elapsed_time_s": 18.09402632713318,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation, from the \"solution\" in the current, in-between of on-net-b.\n\"\n\" the, and the, (in-between of on-net-b. \" \" and \" on-net-b. \"\n(the \" from the \" (with-solution) the, \" (the \" (indraws-a-l. \" and \"draws-b.\u2014a-l. \" and \"a-l. \" \" \" and \"a-l. \" ) \" \" and \" \"and \" \" and \"\np. the \" and \" \" and \" \" and \" \" \" and \" and \" \" and \" \" and \" \" and \" \" and \" \" and \" \" and \" and \" and \" \" and \" \" and \" and, (p. (an \" with-sessions), (the \" with-sessions ) (the \" withfolds-a-l.\nf. to-and-for-a-l. the \" with-sessions \", and \" with-sessions ) (the \" withfolds-a-l.\n- the \" with-sessions \", and \" with-susercontent-b.\n- the \" withfolds-a.\n2. a-z, as, at the, in-between of, in-between of, in-between of on-net-b. and \" the \" and \" on-net-b. \"\n' - and a-z (m. a-z, the \" and, the \" and \" and \", a-z (e-n) \", and, e-n ) \" (, and, a-z (/,- in ) \" (\n1. a-c, and the \" and, and \" and \" and \", a\"a (n-a) \", and, a (in-n-a ) \"\n\n(n-a), and, a (in-n-a ) \"\n:, and (, in-n-a ) \", and, (n-a) and, a (out-n-a ) \"\n\" and, a ((, and ) \" and, a ((n-a) \"\n\ns. (to- and in-between of, between of, in-between of, in\n\" and, \" and \", \"",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 3.2,
    "mem_usage_before": 25770053632,
    "mem_usage_after": 25774854144,
    "elapsed_time_s": 15.70553207397461,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation in the \"2.10\" (I.e., it is so in the \"2.1\" in the \"2.1\" and in the \"2://.in/4x-in.wak2.\n\"in-m.b. and a. and a. and and and \"un- and a., the, the and-\n2. the, and \"e. the, the and-\n2. the, the and the, and the,\"\n2. the and the and the, and the and-\n2://.in/11a-un-b.pj and a. and a. and a. and a. and a. and a. and a. and a. and a. and a. and a. and a\n3. a. and a. and a. and a. and a. and a. and a and a and a and\n3. and a. and a. and a. and a and a and\n3. and a. and, a. and and a. and a. and\n3. and a. and a. and a and a. and a. and a. and\n3. and a. and a and a and a and\n3. and a. and a. and a and a and a and\n3. and a\n3. and a. and a and a and a and a and\n3. and a and a and a and a and\n3://.in/in-w.as and a. and a. and. and a. and, a and a. and a.\n3. and a and a and a and a and a and\n3://.in-d.pj and a(1.a-b. a. and a. and a. and a. and a. and a. and a. and\n3. and a. and, a. and a and a. and,\n3. and a. and a. and, a and, and a and a and\n3. and a. and, a and, and a and a and\n3. and a and,\n3://.in/10-p.a. in a. and a. and a. and a. and, a and a. and\n3. and [1. or ] and a. and a. and, a and a. and a. and\n3.",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 1.1,
    "cpu_usage_after": 3.2,
    "mem_usage_before": 25773821952,
    "mem_usage_after": 25790787584,
    "elapsed_time_s": 15.497120380401611,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation to the other, and direct the ai to use, only the use is quantified in the as-yet-un-remastered and, specifically, (h.g., of \"in-grudge,, the, the, and, the the, in-universe, to and, to, to and, in-universe, on and the, the and, in-un-unse\" and, as, as the, \" to and and, the and, to and, and, the, and, the in-universe, to and, to and, in-un-unse, the and, to and, in-un\",\" \" the, the to and, the, and, in-universe, the and, to and, and in-universe, the and, to and, in... the and, the, and, the. for the. to and, to and, to and, the and, in-un-unse, the and, to and, in-un-unse, the and, to and, in-un-unse, the and, to and, in-un:// (-. and, the to and, to and, the and, in-un-unse, the and, to and, and, in-, the and, to and, in-un-unse, the and, to and, in-un-unse, the and, to and, in-un-unse, the and, to and, in-un-un-unse, the and, to and, in-un-unus, the and, in-un-unus, the. to and, to and, to and, to and, in-un-unus, the and, to and, in-un-unus, the and, to and, in-un-unus:// (n.k.) the and, to and, to and, to and, in-un-unus, the and, to and, inover. to and, to and, to and, to and, in-un-unus, the and, to and, in-un-unus, the and, to and, in-unus, the and, to and, in-un-unus, the and, to and, in-unus, the and, to and, inun-unus, the",
    "model_variation": "quantized",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.6,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 26062176256,
    "mem_usage_after": 25901211648,
    "elapsed_time_s": 8.458191633224487,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-method>\n\n<key>\n\n<value>\n\n<param name=\"hash\" value=\"v1\" />\n\n</key>\n\n</text-generation-method>\n\n<script>\n\n<key>\n\n<value>\n\n<param name=\"hash\" value=\"v2\" />\n\n</key>\n\n</script>\n\n</body>\n\n</html>\n\n</html>\n\n</html>",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.5,
    "mem_usage_before": 25901211648,
    "mem_usage_after": 25885892608,
    "elapsed_time_s": 40.77624320983887,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-data-center/\n\nhttps://www.washingtonpost.com/wp-dyn/content/article/2015/06/14/AR000611_o.html\n\nhttp://www.theguardian.com/politics/2014/jun/01/washington-post-trump-interview-interview-washington-post-trump-interview-washington-post-trump-interview-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post-washington-post",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 1,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.7,
    "mem_usage_before": 25885892608,
    "mem_usage_after": 26149945344,
    "elapsed_time_s": 37.78952431678772,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation and class-based data models. In the case of the GLSL model, this means that the GLSL model is a simple data model that does not rely on linear models of the GLSL. The GLSL model is a simpler, simpler way to model human behavior.\n\nThe most useful aspect of the GLSL model is that it provides a simple, well-structured set of tools that can be used in a variety of scenarios. One example is the GLSL model's ability to automatically generate a simple GLSL model that can be used to create any number of GLSL models.\n\nIn other words, the GLSL model can be used to generate any number of GLSL models. This approach allows for many different scenarios to be used to create complex, simple GLSL models.\n\nHow does GLSL work?\n\nGLSL models are composed of three basic types:\n\nStructural\n\nThe structure of GLSL models is based on the following basic types:\n\nStructural\n\nStructural data is stored in a structured database that is accessible across all GLSL models. This database is often called a model database.\n\nData is stored in a structured database that is accessible across all GLSL models. This database is often called a model database. Classes are defined by class definitions.\n\nData is stored in a structured database that is accessible across all GLSL models. This database is often called a model database. Classes are defined by class definitions. Classes are defined by a class.\n\nData is stored in a structured database that is accessible across all GLSL models. This database is often called a model database. Classes are defined by class definitions. Classes are defined by a class.\n\nData is stored in a structured database that is accessible across all GLSL models. This database is often called a model database. Classes are defined by class definitions. Classes are defined by a class.\n\nData is stored in a structured database that is accessible across all GLSL models. This database is often called a model database. Classes are defined by class definitions. Classes are defined by a class.\n\nData is stored in a structured database that is accessible across all GLSL models. This database is often called a model database. Classes are defined by class definitions. Classes are defined by a class.\n\nData is stored in a structured database that is accessible across all GLSL models",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.6,
    "cpu_usage_after": 1.0,
    "mem_usage_before": 26149945344,
    "mem_usage_after": 26276823040,
    "elapsed_time_s": 26.851731777191162,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation\" attribute is used to control whether or not the target element is loaded. This attribute is also used to set the priority of the element.\n\nThe following table lists the elements in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the target element and the second is the element in the current list of child elements. The first element is the target element and the second is the element in the current list of child elements.\n\nThe first element is the",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 2.1,
    "cpu_usage_after": 1.0,
    "mem_usage_before": 26276823040,
    "mem_usage_after": 26740252672,
    "elapsed_time_s": 26.763476848602295,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-1.0.0.jar) UCHIJAAAA ForgeMicroblock{1.0.0.13} [Forge Microblocks] (ForgeMultipart-1.6.4-1.0.0.13-universal.jar) UCHIJAAAA ForgeWaila{1.0.0.13} [Forge Waila] (ForgeMultipart-1.6.4-1.0.0.13-universal.jar) UCHIJAAAA BuildCraft|Builders{4.0.3} [BC Builders] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA CodeChickenCore{0.5.0} [CodeChicken Core] (minecraft.jar) UCHIJAAAA CodeChickenLib{0.5.0} [CodeChicken Lib] (minecraft.jar) UCHIJAAAA BuildCraft|Energy{4.0.3} [BC Energy] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|Factory{4.0.3} [BC Factory] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|Transport{4.0.3} [BC Transport] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|Silicon{4.0.3} [BC Silicon] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|Factory{4.0.3} [BC Factory] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|Compat{4.0.3} [BuildCraft Compat] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|CompatAddons{4.0.3} [BuildCraft Compat Addons] (buildcraft-A-1.6.4-4.0.3-snapshot.jar) UCHIJAAAA BuildCraft|CompatDeals{4.0.3} [BuildCraft Compat Deals] (buildcraft-A-1.6.4-4.0.3-",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 2,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 0.0,
    "cpu_usage_after": 0.8,
    "mem_usage_before": 26740252672,
    "mem_usage_after": 26747285504,
    "elapsed_time_s": 26.672773361206055,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation> <col-sm-1> <h1>The last time you were out of town.</h1> <p>From your first date with me</p> <p>You were a fun, kind, kind, kind person.</p> <p>You were always smiling when you walked in the door.</p> <p>You always seemed to have the best of you.</p> <p>You always had a smile on your face.</p> <p>You always wanted to have fun.</p> </div> </div> </div> </div> </div> </div> </div> </div> <div class=\"separator-wrapper\"> <div class=\"separator-content\"> <div class=\"separator-header\"> <div class=\"separator-header-text-generation\" data-toggle=\"on\"></div> <div class=\"separator-header-text-generation-text\"> <div class=\"separator-header-text-generation-text-generation\" data-toggle=\"on\"></div> <div class=\"separator-header-text-generation-text-generation-text-generation-text-generation-text-generation\" data-toggle=\"off\"></div> <div class=\"separator-header-text-generation-text-generation-text-generation-text-generation-text-generation-text-generation\" data-toggle=\"off\"></div> </div> <div class=\"separator-header-text-generation-text-generation-text-generation-text-generation-text-generation\" data-toggle=\"off\"></div> <div class=\"separator-header-text-generation-text-generation-text-generation-text-generation-text-generation\" data-toggle=\"off\"></div> <div class=\"separator-header-text-generation-text-generation-text-generation-text-generation-text-generation\" data-toggle=\"off\"></div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div class=\"separator-wrapper\"> <div class=\"separator-content\"> <div class=\"separator-header\"> <div class=\"separator-header-text-generation",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 1.4,
    "cpu_usage_after": 1.5,
    "mem_usage_before": 26747285504,
    "mem_usage_after": 26745540608,
    "elapsed_time_s": 25.161892890930176,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-manager.js\" > < / script >\n\n// Create and modify the generated output\n\nvar output = new Output ();\n\nvar output-data = {\n\nname : \" \",\n\nvalue : \" \",\n\nsrc_name : \" src \",\n\nsrc_name_dir : \" src \",\n\ndest_name : \" dest \",\n\ndest_name_dir : \" dest_dir \",\n\ndest_name_size : 10,\n\nsrc_name : \" src_name \",\n\nsrc_name_size_min : 0,\n\nsrc_name : \" src_name_min \",\n\nsrc_name_size_max : 0,\n\nsrc_name : \" src_name_max \",\n\nsrc_name_size : 50,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_min : 0,\n\nsrc_name : \" src_name_size_min \",\n\nsrc_name_size_max : 0,\n\nsrc_name : \" src_name_size_max \",\n\nsrc_name_size_size : 50,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_min : 0,\n\nsrc_name : \" src_name_size_min \",\n\nsrc_name_size_max : 0,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_size : 50,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_size : 50,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_min : 0,\n\nsrc_name : \" src_name_size_min \",\n\nsrc_name_size_max : 0,\n\nsrc_name : \" src_name_size_max \",\n\nsrc_name_size_size : 50,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_size : 50,\n\nsrc_name : \" src_name_size \",\n\nsrc_name_size_size : 50,\n\nsrc_name : \" src_name_",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 2.2,
    "cpu_usage_after": 1.7,
    "mem_usage_before": 26745540608,
    "mem_usage_after": 26753413120,
    "elapsed_time_s": 25.323700428009033,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-type=rss; charset=UTF-8; charset-family=US; language=us-ascii; xmlns=3D\"http://www.w3.org/2001/XMLSchema-instance-3D\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-3D\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-4\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-5\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-6\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-7\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-8\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-9\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-10\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-11\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-12\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-13\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-14\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-15\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-16\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-17\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-18\" xmlns=3D\"http://www.w3.org/1999/XMLSchema-instance-19\" xmlns=3D\"http://www.w3.org/",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 4,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 2.3,
    "cpu_usage_after": 1.5,
    "mem_usage_before": 26753413120,
    "mem_usage_after": 26758590464,
    "elapsed_time_s": 25.39058518409729,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation\n\n<img src=\"//www.pinterest.com/pin/3328124468683545/href?ref=https%3A%2F%2Fwww.pinterest.com%2Fpin%2F3328124468683545%2Fstyle%2F1%2F1.0%3A%2F2Fwww.pinterest.com%2Fpin%2F3328124468683545%2Fstyle%2F0%3A%2Fwww.pinterest.com%2Fpin%2F3328124468683545%2Fstyle%2F1%2F1.0%3A%2Fwww.pinterest.com%2Fpin%2F3328124468683545%2Fstyle%2F2%2F1.0%3A%2Fwww.pinterest.com%2Fpin%2F3328124468683545%2Fstyle%2F3%2F0%3A%2Fwww.pinterest.com%2Fpin%2F3328124468683545%2Fstyle%3%2F0%3A%2Fwww.pinterest.com%2Fpin%3%2F3328124468683545%3%3%3%3%3%3%2%3%2%3%3%2%2%3%3%2%3%3%2%2%3%3%3%2%3%3%2%2%3%2%3%2%2%3%3%2%2%3%3%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3%2%2%3",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 0,
    "cpu_usage_before": 0.7,
    "cpu_usage_after": 2.8,
    "mem_usage_before": 26758590464,
    "mem_usage_after": 26760929280,
    "elapsed_time_s": 24.412371158599854,
    "is_correct": 0,
    "input_text": "Solve 24 = 1601*c - 1605*c for c.\\n",
    "reference_solution": "-6",
    "generated_text": "text-generation-id=1\n\nNote that the data is provided in a format that does not support binary files. For example, the following is a binary file that contains the data in \"Data: fileName\", \"File: fileName.txt\", and \"Data: fileName.csv\", and then it is compressed and stored in the local memory of the device. The data is compressed in the \"Data: fileName.txt\" format, and stored in the local memory of the device.\n\nNote that the data is provided in a format that does not support binary files. For example, the following is a binary file that contains the data in \"Data: fileName\", \"File: fileName.txt\", and then it is compressed and stored in the local memory of the device. The data is compressed in the \"Data: fileName.txt\" format, and stored in the local memory of the device. \"Data: fileName.txt\" is the full name of the file, and is compressed. The data is stored in the local memory of the device.\n\nThe following format is used to support the data type of a device. For example, \"Data: fileName.txt\" is compressed in the \"Data: fileName.txt\" format, and stored in the local memory of the device. The data type of the device is \"Text: \".\n\nNote that the data is provided in a format that does not support binary files. For example, the following is a binary file that contains the data in \"Data: fileName\", \"File: fileName.txt\", and then it is compressed and stored in the local memory of the device. The data is compressed in the \"Data: fileName.txt\" format, and stored in the local memory of the device. \"Data: fileName.txt\" is the full name of the file, and is compressed. The data is stored in the local memory of the device.\n\nNote that the data is provided in a format that does not support binary files. For example, the following is a binary file that contains the data in \"Data: fileName\", \"File: fileName.txt\", and then it is compressed and stored in the local memory of the device. The data is compressed in the \"Data: fileName.txt\" format, and stored in the local memory of the device. \"Data: fileName.txt\" is the full name of the file, and is compressed. The data is stored in",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 1,
    "cpu_usage_before": 8.7,
    "cpu_usage_after": 2.8,
    "mem_usage_before": 26760929280,
    "mem_usage_after": 26819026944,
    "elapsed_time_s": 24.298667669296265,
    "is_correct": 0,
    "input_text": "Solve 657 = -220*t + 1086*t + 22307 for t.\\n",
    "reference_solution": "-25",
    "generated_text": "text-generation-classifier.css\" > < div class = \"child-item-group\" > < div class = \"child-item-group-icon\" > < a href = \"https://www.reddit.com/r/The_Donald/comments/4s8gj3/im_going_to_get_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_comments/4s8gj3/i_got_all_my_reddit_",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  },
  {
    "model_name": "GPT2LMHeadModel",
    "num_threads": 8,
    "max_ram_mb": null,
    "example_index": 2,
    "cpu_usage_before": 8.7,
    "cpu_usage_after": 2.8,
    "mem_usage_before": 26819026944,
    "mem_usage_after": 26761408512,
    "elapsed_time_s": 24.520120859146118,
    "is_correct": 0,
    "input_text": "Solve -11*y - 263*y + 3162 = -88*y for y.\\n",
    "reference_solution": "17",
    "generated_text": "text-generation-mode=2\"); // Start the process in the background with the new generation mode if (input.stop() > 0) { // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Get the current generation mode if (input.stop() > 0) { input.stop(); } // Start the process in the background with the new generation mode if (input.stop() > 0) { input.stop(); }\n\nRAW Paste Data\n\n// Start the process in the background with the new generation mode if(input.stop() < 0) { // Start the",
    "model_variation": "pruned",
    "model_base": "openai-community/gpt2"
  }
]